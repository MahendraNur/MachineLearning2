# -*- coding: utf-8 -*-
"""223443083_Mahendra_TugasMandiri.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xml0JPnwHPlRWF6JW8DlcgsY5Qh_4v1Z

# Tahap 1: Pemahaman Data Awal (Initial Data Understanding)

Mengapa Tahapan Ini Penting?
Sebelum melakukan pembersihan atau pelatihan model, kita harus benar-benar memahami data yang kita miliki. Ini seperti seorang mekanik yang ingin memperbaiki mobil—tentu ia perlu tahu jenis, kondisi, dan bagian-bagian mobil sebelum mulai menyetel.

Tahap ini membantu kita:
- Mengenali struktur dan isi dataset
- Menemukan nilai yang hilang atau mencurigakan
- Memahami korelasi potensial antara fitur dengan target (transmission)
- Memutuskan fitur mana yang relevan atau perlu dihapus

# Deskripsi Sistem: Prediksi Jenis Transmisi Mobil Berdasarkan Fitur-Fitur Kendaraan

1. Abstrak

Sistem ini dirancang untuk memprediksi jenis transmisi mobil (Manual atau Automatic) berdasarkan sejumlah atribut mobil seperti tahun pembuatan, harga jual, jenis bahan bakar, dan nama/model mobil. Prediksi ini berguna bagi dealer, pembeli mobil bekas, maupun platform jual-beli mobil yang ingin memberikan informasi lebih cepat dan akurat mengenai spesifikasi mobil.

2. Tujuan Sistem

- Membantu klasifikasi otomatis jenis transmisi untuk mobil bekas
- Meningkatkan efisiensi pencarian dan filter dalam aplikasi jual beli
- Memberikan insight tren jenis transmisi berdasarkan spesifikasi mobil

3. Metodologi dan Cara Kerja

  1. Pengumpulan Data: Dataset mobil bekas dikumpulkan dari sumber publik (misalnya Kaggle).
  2. Pra-pemrosesan: Dilakukan pembersihan data, encoding untuk data kategorikal, dan normalisasi numerik jika diperlukan.
  3. Modeling: Menggunakan algoritma klasifikasi seperti Decision Tree, Random Forest, atau Logistic Regression untuk mempelajari pola dari data.
  4. Evaluasi: Menilai akurasi prediksi model terhadap data test.
  5. Output: Model akan memprediksi apakah mobil cenderung bertransmisi Manual atau Automatic berdasarkan input fitur.

4. Atribut Kunci yang Dianalisis

make_year → Tahun mobil diproduksi. Mobil yang lebih baru biasanya lebih banyak menggunakan transmisi otomatis, sedangkan mobil lama cenderung manual. Jadi, tahun produksi bisa menjadi indikator kuat.

mileage_kmpl → Menggambarkan efisiensi bahan bakar. Transmisi otomatis dan manual dapat menghasilkan efisiensi yang berbeda tergantung mesin dan teknologi, sehingga bisa berpengaruh.

engine_cc → Kapasitas mesin. Mesin dengan cc besar biasanya digunakan pada mobil performa tinggi, yang cenderung menggunakan transmisi otomatis. Jadi, fitur ini bisa berkorelasi dengan jenis transmisi.

fuel_type → Jenis bahan bakar (bensin, solar, listrik, dll). Mobil listrik misalnya, hampir selalu otomatis. Jadi jenis bahan bakar bisa memberikan informasi tambahan terhadap tipe transmisi.

brand → Merek mobil. Beberapa brand lebih sering memproduksi mobil otomatis atau manual tergantung segmentasi pasarnya. Jadi, brand bisa menjadi indikator kebiasaan desain.

price_usd → Digunakan untuk Analisis Unvariant jadi lewat price_usd

5. Atribut yang Diabaikan / Dihapus

owner_count : Tidak langsung berhubungan dengan jenis transmisi

accidents_reported : Korelasi terhadap transmisi lemah

service_history : Banyak data kosong (null), dan juga tidak berpengaruh langsung

insurance_valid : Status asuransi tidak berkaitan dengan jenis transmisi

color : Warna mobil tidak logis memengaruhi sistem transmisi

1. Persiapan & Import Library
"""

!pip install pandas numpy matplotlib seaborn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""2. Load Dataset"""

from google.colab import files
uploaded = files.upload()

"""# Menampilkan 5 baris pertama dari dataset"""

df = pd.read_csv("used_car_price_dataset.csv")
print("Lima baris pertama dataset:")
df.head()

"""# Menampilkan informasi ringkas tentang DataFrame"""

print("\nInformasi struktural dataset:")
df.info()

"""# Menampilkan jumlah baris dan kolom"""

print(f"\nDimensi dataset (baris, kolom): {df.shape}")

"""# Statistik Deskriptif pada Dataset Mobil
Perintah df.describe() menghasilkan ringkasan statistik untuk kolom numerik dalam dataset mobil bekas.

Tujuan: Memberikan wawasan awal terhadap karakteristik fitur-fitur numerik seperti tahun pembuatan, kapasitas mesin, dan efisiensi bahan bakar.

Penjelasan Output:
count: Jumlah data valid (tidak kosong/null). Menunjukkan kelengkapan data di tiap kolom.

mean: Rata-rata dari kolom tersebut.
Contoh: Rata-rata mileage_kmpl bisa memberi gambaran umum efisiensi bahan bakar kendaraan.

std: Standar deviasi — menunjukkan seberapa bervariasi data.
Misalnya, engine_cc dengan deviasi besar berarti banyak variasi ukuran mesin dalam dataset.

min: Nilai minimum.
Contoh: make_year minimum bisa menunjukkan tahun mobil tertua yang ada dalam dataset.

25%, 50% (median), 75%: Kuartil yang membagi data menjadi empat bagian.
Median (50%) dapat memberi gambaran titik tengah distribusi data.
Perbedaan besar antara median dan mean bisa menunjukkan distribusi miring atau outlier.

max: Nilai maksimum dalam kolom.
Contoh: engine_cc tertinggi bisa jadi mobil sport atau SUV bertenaga besar.
"""

# Menampilkan statistik deskriptif untuk kolom numerik
print("\nStatistik deskriptif untuk kolom numerik:")
df.describe()

"""# Tahap 2: Pembersihan Data (Data Cleaning)

Mengapa Tahapan Ini Penting?
Ini adalah fase di mana kita secara aktif memperbaiki dan menyaring data mentah agar siap digunakan oleh algoritma Machine Learning. Model tidak bisa membedakan mana data yang masuk akal dan mana yang penuh kesalahan—itu tugas kita.

Tahapan pembersihan ini meningkatkan kualitas, akurasi, dan keandalan prediksi dengan memastikan model hanya belajar dari informasi yang benar dan relevan, bukan dari data yang tidak konsisten, salah, atau tidak bermakna.

Implementasi di Google Colab: Pembersihan Data Mobil

Kita akan melakukan beberapa tahapan pembersihan data secara sistematis, termasuk penggantian nama kolom, penanganan nilai kosong, penghapusan fitur yang tidak relevan, dan sebagainya.

2.1. Penggantian Nama Kolom (Column Renaming)
Pentingnya:
Nama kolom seperti acc_rptd atau own_ct mungkin singkat, tapi tidak jelas artinya. Nama yang deskriptif seperti accidents_reported atau owner_count lebih mudah dipahami dan membuat kode lebih terbaca, baik oleh diri kita sendiri di masa depan maupun oleh rekan tim lain.

Strategi:
Kita membuat kamus (dictionary) Python yang memetakan nama-nama lama ke nama-nama baru yang lebih jelas. Lalu kita gunakan metode .rename() pada DataFrame.
"""

# Pemetaan nama
column_mapping = {
    'make_year': 'Make_Year',
    'mileage_kmpl': 'Mileage_Kmpl',
    'engine_cc': 'Engine_CC',
    'fuel_type': 'Fuel_Type',
    'owner_count': 'Owner_Count',
    'price_usd': 'Price_USD',
    'brand': 'Brand',
    'transmission': 'Transmission',
    'color': 'Color',
    'service_history': 'Service_History',
    'accidents_reported': 'Accidents_Reported',
    'insurance_valid': 'Insurance_Valid'
}

# Ubah nama kolom
df.rename(columns=column_mapping, inplace=True)

print("Nama kolom setelah diubah:")
print(df.columns)

print("\nInformasi struktural dataset:")
df.info()

"""# 2.2. Penghapusan Kolom yang Tidak Relevan (Dropping Irrelevant Columns)

Pentingnya: Tidak semua data berguna. Beberapa kolom justru dapat menurunkan performa model.

- owner_count : Tidak memiliki hubungan langsung dengan sistem transmisi. Banyak atau sedikitnya pemilik sebelumnya tidak memengaruhi jenis transmisi mobil.

- accidents_reported : Jumlah kecelakaan yang pernah terjadi pada mobil. Korelasi dengan transmisi sangat lemah, dan bisa jadi data ini lebih cocok untuk analisis risiko atau nilai jual kembali.

- service_history : Riwayat servis. Banyak nilai kosong (missing/NaN), dan secara langsung tidak menunjukkan hubungan kuat dengan jenis transmisi.

- insurance_valid : Status asuransi aktif atau tidak. Ini lebih bersifat administratif dan tidak berkaitan dengan teknologi transmisi kendaraan.

- color : Warna mobil. Secara logika, warna tidak mungkin memengaruhi jenis transmisi, sehingga diabaikan dalam analisis.

Strategi: Kita buat daftar berisi nama-nama kolom yang akan dihapus, lalu gunakan metode .drop().
"""

# Daftar kolom yang ingin dihapus karena tidak relevan terhadap prediksi transmisi
columns_to_drop = [
    'Owner_Count',         # Tidak langsung berhubungan dengan jenis transmisi
    'Accidents_Reported',  # Korelasi terhadap transmisi lemah
    'Service_History',     # Banyak data kosong (null), dan tidak berpengaruh langsung
    'Insurance_Valid',     # Status asuransi tidak berkaitan dengan jenis transmisi
    'Brand',               # Sulit untuk mengetahui jika lewat nama
    'Color',               # Warna mobil tidak logis memengaruhi sistem transmisi
]

# Menghapus kolom-kolom tersebut dari DataFrame
df.drop(columns=columns_to_drop, inplace=True)

# Menampilkan informasi setelah penghapusan
print(f"\nJumlah kolom setelah penghapusan: {df.shape[1]}")
print("Kolom yang tersisa:")
print(df.columns)

print("\nInformasi struktural dataset:")
df.info()

"""# 2.3. Penanganan Nilai yang Hilang (Handling Missing Values)

Pentingnya: Sebagian besar algoritma machine learning tidak dapat memproses data yang mengandung nilai NaN (Not a Number). Mengabaikannya akan menyebabkan error. Menghapus baris yang memiliki nilai hilang bisa menjadi pilihan, tetapi jika data yang hilang banyak, kita akan kehilangan informasi berharga. Oleh karena itu, kita perlu strategi pengisian (imputation) yang cerdas.

Strategi:

1. Deteksi: Gunakan df.isnull().sum() untuk menghitung jumlah nilai hilang di setiap kolom.
2. Dikarenakan disini tidak ada nilai Null maka kita akan lanjut ke langkah berikutnya
"""

print(df.isnull().sum())

"""# 2.4. Penanganan Inkonsistensi dan Konversi Tipe Data (Dataset Mobil)

Konsistensi adalah kunci. Komputer menganggap "Manual", "manual", dan "MANUAL" sebagai tiga kategori yang berbeda. Jika tidak diseragamkan, maka analisis akan salah atau membingungkan.
Selain itu, memastikan tipe data sudah benar—misalnya:

Kolom transmission diubah dari teks menjadi angka (Manual → 0, Automatic → 1)

Kolom fuel juga diubah ke angka (misalnya: Bensin → 0, Diesel → 1, Listrik → 2)

Ini penting untuk efisiensi memori, kecepatan proses, dan agar data bisa dibaca dengan benar oleh algoritma machine learning.
"""

df['Transmission'] = df['Transmission'].map({'Automatic': 1, 'Manual': 0})

print("\nNilai unik pada kolom target setelah konversi:")
print(df['Transmission'].value_counts())

"""# Tahap 3: Analisis Data Eksploratif (EDA)

Mengapa Tahapan Ini Penting?
Jika proses pembersihan data diibaratkan seperti merapikan sebuah bengkel mobil—menghilangkan oli bocor, memungut baut yang tercecer—maka EDA (Exploratory Data Analysis) adalah saat kita mulai menelusuri setiap komponen mobil, melihat bagaimana performanya, dan memahami bagaimana satu bagian mempengaruhi bagian lainnya.

Pada dataset mobil yang sedang kita analisis, EDA menjadi langkah penting karena kita ingin memahami secara menyeluruh karakteristik mobil-mobil tersebut sebelum melakukan pemodelan. Beberapa tujuan utama dari EDA yang kita lakukan antara lain:

Memahami Distribusi Variabel

Mengidentifikasi Outlier

Menemukan Hubungan Antara Variabel

Menguji Asumsi

Menghasilkan Hipotesis untuk Tahapan Selanjutnya
"""

# Mengimpor pustaka untuk visualisasi
import matplotlib.pyplot as plt
import seaborn as sns

# Mengatur gaya visualisasi agar lebih menarik
sns.set_style('whitegrid')

"""# 3.1. Analisis Univariat (Menganalisis Satu Variabel)

Pentingnya:
Memahami karakteristik tiap variabel satu per satu sangat penting sebelum menganalisis hubungan antar variabel. Analisis univariat membantu:

Mengetahui distribusi nilai dari suatu fitur (contoh: harga mobil).

Melihat apakah nilai-nilainya tersebar normal atau tidak.

Menemukan adanya pencilan (outlier).

Memberi gambaran awal sebelum analisis lebih kompleks.
"""

plt.figure(figsize=(14, 5))

# Plot 1: Histogram untuk Price_USD
plt.subplot(1, 2, 1)
sns.histplot(df['Price_USD'], kde=True, bins=30)
plt.title('Distribusi Harga Mobil (USD)')
plt.xlabel('Harga (USD)')
plt.ylabel('Frekuensi')

# Plot 2: Box Plot untuk Price_USD
plt.subplot(1, 2, 2)
sns.boxplot(x=df['Price_USD'])
plt.title('Box Plot Harga Mobil (USD)')
plt.xlabel('Harga (USD)')

plt.tight_layout()
plt.show()

"""Interpretasi:
Dari plot ini, kita bisa melihat jenis bahan bakar mobil yang paling umum digunakan, apakah lebih banyak mobil berbahan bakar bensin (petrol), diesel, atau jenis lainnya.
Visualisasi ini membantu kita memahami preferensi pasar atau tren industri otomotif berdasarkan jenis bahan bakarnya.
"""

plt.figure(figsize=(8, 5))
sns.countplot(y=df['Fuel_Type'], order=df['Fuel_Type'].value_counts().index)
plt.title('Jumlah Mobil Berdasarkan Jenis Bahan Bakar')
plt.xlabel('Jumlah Mobil')
plt.ylabel('Jenis Bahan Bakar')
plt.show()

"""# 3.2. Analisis Bivariat (Menganalisis Hubungan Dua Variabel)

Pentingnya:
Ini bagian penting dari EDA, karena kita mencoba menghubungkan fitur kategorikal (Transmission) dengan target numerik (Price_USD).
"""

plt.figure(figsize=(8, 6))
sns.boxplot(x='Transmission', y='Price_USD', data=df)
plt.title('Hubungan antara Jenis Transmisi dan Harga Mobil')
plt.xlabel('Jenis Transmisi')
plt.ylabel('Harga Mobil (USD)')
plt.show()

print("\nInformasi struktural dataset:")
df.info()

"""Membandingkan jumlah mobil berdasarkan jenis transmisi, dan memecahnya berdasarkan kategori tertentu."""

plt.figure(figsize=(10, 6))
sns.countplot(y='Fuel_Type', hue='Transmission', data=df, order=df['Fuel_Type'].value_counts().index)
plt.title('Distribusi Mobil Berdasarkan Jenis Transmisi dan Jenis Bahan Bakar')
plt.xlabel('Jumlah Mobil')
plt.ylabel('Jenis Transmisi')
plt.legend(title='Jenis Bahan Bakar')
plt.show()

"""Plot ini memungkinkan kita melihat secara visual distribusi jenis transmisi (manual dan automatic) di setiap jenis bahan bakar (Fuel_Type).

# 3.3. Analisis Multivariat (Melihat Banyak Variabel Sekaligus)

Pentingnya: Visualisasi korelasi sangat penting dalam analisis data karena memungkinkan kita memahami hubungan kompleks antara variabel numerik dalam dataset. Dalam konteks dataset mobil, ini membantu kita mengidentifikasi variabel mana saja yang saling berkaitan — misalnya apakah mobil yang lebih baru cenderung memiliki harga lebih tinggi, atau apakah jarak tempuh mempengaruhi harga jual mobil.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Memilih hanya kolom numerik dari dataset mobil
numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns

# Membuat heatmap korelasi
plt.figure(figsize=(12, 10))
correlation_matrix = df[numerical_cols].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Heatmap Korelasi Antar Variabel Numerik pada Dataset Mobil')
plt.show()

"""Interpretasi:
Heatmap ini berguna untuk:

Melihat fitur mana yang paling berkorelasi dengan variabel target, yaitu Transmission.

Mengetahui kekuatan hubungan antara fitur numerik (misal: Engine_CC, Mileage_Kmpl) terhadap jenis transmisi mobil.

Mendeteksi korelasi tinggi antar fitur numerik lainnya yang bisa mempengaruhi hasil model jika terjadi multikolinearitas.
"""

# Tampilkan semua kolom tanpa dipotong
pd.set_option('display.max_columns', None)           # Jangan batasi jumlah kolom
pd.set_option('display.expand_frame_repr', False)    # Jangan membungkus baris

# Sekarang head() akan menampilkan semua kolom
df.head(20)

"""# Tahap 4: Persiapan Data untuk Pemodelan (Data Preparation for Modeling)
Mengapa Tahapan Ini Penting?
Dalam machine learning, algoritma tidak dapat memahami data dalam bentuk teks seperti "Automatic", "Manual", atau "Diesel", "Petrol", dan sebagainya. Semua input harus dikonversi menjadi angka karena algoritma hanyalah serangkaian fungsi matematis. Oleh karena itu, kita perlu mengubah semua fitur kategorikal menjadi format numerik. Selain itu, untuk memastikan evaluasi model yang adil dan akurat, kita juga perlu membagi data menjadi dua bagian: data latih (untuk melatih model) dan data uji (untuk mengevaluasi kinerjanya). Proses ini memastikan bahwa model dapat menggeneralisasi dan tidak hanya menghafal data

# Tahap 4.1: Encoding Variabel Kategorikal

Mengapa Tahapan Ini Penting?
Dalam dataset, beberapa kolom memiliki data dalam bentuk kategori teks, seperti Fuel_Type yang berisi nilai seperti Petrol, Diesel, atau Electric.
Namun, algoritma machine learning hanya memahami angka, bukan teks. Oleh karena itu, kita perlu mengubah kategori tersebut menjadi representasi numerik.
"""

# Cek nilai unik dan missing value pada kolom Fuel_Type
print("Kategori unik pada kolom Fuel_Type:", df['Fuel_Type'].unique())
if df['Fuel_Type'].isnull().any():
    print("Terdapat missing value pada kolom Fuel_Type, akan diisi dengan 'Unknown'")
    df['Fuel_Type'].fillna('Unknown', inplace=True)

# One-Hot Encoding pada kolom Fuel_Type
# Kami akan melakukan ini setelah pemisahan data agar tidak terjadi data leakage
# Tapi untuk contoh ini, kita lakukan encoding di awal untuk kemudahan
df_encoded = pd.get_dummies(df, columns=['Fuel_Type'], drop_first=False)

# Tampilkan info hasil encoding
print("\nKolom setelah One-Hot Encoding:", df_encoded.columns.tolist())
print("Dimensi dataset setelah encoding:", df_encoded.shape)
print("\n5 Data teratas setelah encoding:")
print(df_encoded.head())

"""# 4.2. Pemisahan Fitur (X) dan Target (y)

Pentingnya:
Pemisahan ini penting untuk memisahkan antara fitur-fitur yang akan digunakan untuk memprediksi (X) dan label atau target yang ingin diprediksi (y).
Dalam kasus ini, kita ingin memprediksi jenis bahan bakar (Fuel_Type) berdasarkan fitur lainnya seperti Year, dll.
"""

# Memisahkan fitur (X) dan target (y) dari data yang sudah di-encoded
# 'Transmission' adalah target, dan semua kolom lainnya adalah fitur
X = df_encoded.drop('Transmission', axis=1)
y = df_encoded['Transmission']

# Menampilkan bentuk/ukuran data fitur dan target
print("Bentuk fitur (X):", X.shape)
print("Bentuk target (y):", y.shape)

# Menampilkan 5 data pertama sebagai contoh
print("\nContoh data fitur (X):")
print(X.head())
print("\nContoh data target (y):")
print(y.head())

"""# 4.3. Pembagian Data Latih dan Data Uji (Train-Test Split)

Pentingnya: Ini adalah langkah paling fundamental dalam validasi model. Kita melatih model pada data latih dan kemudian menguji kinerjanya pada data uji yang belum pernah "dilihat" sebelumnya. Ini mensimulasikan bagaimana model akan berkinerja di dunia nyata dan membantu kita mendeteksi overfitting (ketika model terlalu hafal data latih dan buruk pada data baru).

Strategi: Menggunakan fungsi train_test_split dari scikit-learn. Proporsi umum adalah 80% untuk data latih dan 20% untuk data uji.
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print("Ukuran data latih:", X_train.shape)
print("Ukuran data uji:", X_test.shape)

print("Isi numerical_cols:", numerical_cols)
print("Kolom yang tersedia:", X_train.columns.tolist())

"""# 4.4. Penskalaan Fitur (Feature Scaling)
Pentingnya:
Beberapa algoritma machine learning seperti Regresi Logistik, SVM, dan KNN sangat sensitif terhadap skala numerik antar fitur. Dalam dataset ini, fitur-fitur seperti Engine_CC (misalnya bernilai ribuan) dan Mileage_Kmpl (biasanya bernilai belasan hingga puluhan) memiliki skala yang sangat berbeda. Tanpa proses penskalaan, algoritma bisa lebih memprioritaskan fitur yang nilainya besar (seperti Price_USD atau Engine_CC) hanya karena skala nilainya, bukan karena pentingnya informasi.

Strategi:
Untuk menghindari bias akibat skala yang berbeda, kita melakukan penskalaan menggunakan StandardScaler dari scikit-learn, yaitu teknik standarisasi dengan cara mengubah data menjadi distribusi dengan rata-rata 0 dan standar deviasi 1.
"""

from sklearn.preprocessing import StandardScaler

# Inisialisasi scaler
scaler = StandardScaler()

# Pilih kolom numerik yang perlu di-scale (kolom biner dari encoding tidak perlu)
numerical_cols = ['Make_Year', 'Mileage_Kmpl', 'Engine_CC', 'Price_USD']
categorical_cols = ['Fuel_Type_Diesel', 'Fuel_Type_Petrol'] # Tambahkan kolom hasil encoding lainnya jika ada

# Scaling data numerik di data latih dan uji
X_train_scaled = scaler.fit_transform(X_train[numerical_cols])
X_test_scaled = scaler.transform(X_test[numerical_cols])

# Gabungkan kembali data numerik yang sudah di-scale dengan data kategorikal yang tidak di-scale
X_train_final = pd.DataFrame(X_train_scaled, index=X_train.index, columns=numerical_cols)
X_test_final = pd.DataFrame(X_test_scaled, index=X_test.index, columns=numerical_cols)

# Tambahkan kembali kolom kategorikal ke DataFrame final
X_train_final = pd.concat([X_train_final, X_train[categorical_cols]], axis=1)
X_test_final = pd.concat([X_test_final, X_test[categorical_cols]], axis=1)

print("\nData siap untuk pemodelan.")
print("\nContoh data latih final:")
print(X_train_final.head())

"""#Tahap 5: Pemilihan dan Pelatihan Model

Mengapa Tahapan Ini Penting?

Tidak ada satu model yang sempurna untuk semua masalah. Dengan melatih beberapa jenis model yang berbeda, kita dapat membandingkan kekuatan dan kelemahan masing-masing dan memilih yang paling sesuai untuk kasus penggunaan kita.

Strategi Pemilihan Model:

Kita akan mencoba tiga kandidat kuat untuk masalah klasifikasi biner ini:

Regresi Logistik (Logistic Regression): Model yang sederhana, cepat, dan sangat mudah diinterpretasikan. Ini adalah baseline yang sangat baik untuk memulai.

Random Forest Classifier: Model ensemble yang kuat, terdiri dari banyak "pohon keputusan". Sangat baik dalam menangani hubungan non-linear dan memberikan metrik "pentingnya fitur".

Gradient Boosting Classifier (LightGBM): Model ensemble canggih yang seringkali memberikan akurasi tertinggi. Bekerja dengan membangun pohon secara berurutan, di mana setiap pohon baru mencoba memperbaiki kesalahan pohon sebelumnya.

Implementasi Pelatihan:
"""

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import lightgbm as lgb

# Inisialisasi model
log_reg = LogisticRegression(random_state=42)
random_forest = RandomForestClassifier(random_state=42)
lgbm = lgb.LGBMClassifier(random_state=42)

# Melatih model pada data latih yang sudah diproses
print("Melatih model Regresi Logistik...")
log_reg.fit(X_train_final, y_train)

print("Melatih model Random Forest...")
random_forest.fit(X_train_final, y_train)

print("Melatih model LightGBM...")
lgbm.fit(X_train_final, y_train)

print("\nSemua model telah berhasil dilatih.")

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Membuat prediksi pada data uji
y_pred_log_reg = log_reg.predict(X_test_final)
y_pred_rf = random_forest.predict(X_test_final)
y_pred_lgbm = lgbm.predict(X_test_final)

# Mengevaluasi setiap model
print("--- Laporan Klasifikasi: Regresi Logistik ---")
print(classification_report(y_test, y_pred_log_reg))

print("\n--- Laporan Klasifikasi: Random Forest ---")
print(classification_report(y_test, y_pred_rf))

print("\n--- Laporan Klasifikasi: LightGBM ---")
print(classification_report(y_test, y_pred_lgbm))

print(classification_report(y_test, y_pred_log_reg, zero_division=0))

# Mendapatkan pentingnya fitur dari model Random Forest
feature_importances = pd.DataFrame({
    'feature': X_train_final.columns,
    'importance': random_forest.feature_importances_
}).sort_values('importance', ascending=False)

# Visualisasi 10 fitur terpenting
plt.figure(figsize=(10, 8))
sns.barplot(x='importance', y='feature', data=feature_importances.head(10))
plt.title('10 Fitur Paling Penting Menurut Random Forest')
plt.xlabel('Pentingnya Fitur')
plt.ylabel('Fitur')
plt.show()